{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🖼️ Meme Generator Lab: Student Lab\n",
    "## Getting Started\n",
    "Ref repository: https://github.com/IFML-UT/MLLAcademy-2025\n",
    "\n",
    "**What we're going to do inside of this notebook:**\n",
    "\n",
    "> This notebook is used to simulate student interactions with the meme generator pipeline.\n",
    "Use it to validate that the full captioning stack is working before you begin creating a meme of your own.\n",
    "\n",
    "## 🗺️ Roadmap for the entire lab:\n",
    "> The lab is broken down into 3 major sections:\n",
    "\n",
    "1. **Working with LLMs & Inference**: You'll use an open source large language model (LLM) to generate a meme based on general topics or themes. You'll select the best caption from 3 results. We'll be using Meta's `Llama` model family for this text generation\n",
    "\n",
    "\n",
    "2. **Multi-modal Generative AI:** With your caption from the first part of the lab, you will use OpenCLIP to query the top 3 matches from a library of popular meme images to select the best image, based on your text caption. You'll understand what multi-modal means, and how a pre-trained vision transformer model like `ViT-B-32` can return relevant images based on text inputs.\n",
    "\n",
    "3. **Combine both the generated text and best image into your final AI-meme for your finished product.**\n",
    "\n",
    "\n",
    "### ⚙️ How It Works:\n",
    "- Inputs a freeform meme idea or phrase\n",
    "- Classifies it into a pre-approved topic\n",
    "- Uses LLaMA 3.1 8B Instruct (via Hugging Face) to generate 3 clean meme captions\n",
    "- Filters for profanity or off-topic content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup -- Run this cell first to install dependencies and import necessary modules.\n",
    "# This script is designed to be run in a Jupyter notebook environment, such as Google Colab or a local Jupyter setup.\n",
    "# It installs required packages and imports functions for generating safe captions from images.\n",
    "\n",
    "!git clone https://github.com/IFML-UT/MLLAcademy-2025.git\n",
    "# 🛠️ Install dependencies (for Colab or Drive-mount workflows)\n",
    "\n",
    "# --- this cell will create a folder called MLLAcademy-2025 in your current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Requirements & Configure Hugging Face Inference API Token: \n",
    "To help keep this lab computationally light and flexible for our lab use, we are using Hugging Face inference token (generated by IFML) for your use during this week. \n",
    "- API stands for application programing interface, once configured it allows two different software applications communicate and send data to one another. \n",
    "- This secret token will expire after this week. If you would like to continue to run this lab later on your own, you can do so by creating a free HuggingFace account, creating a token within the free tier (https://huggingface.co/settings/tokens) and then pasting your new token into the cell's `getpass` feature below. \n",
    "\n",
    "> “Paste your Hugging Face API token (provided to you) in the cell below when prompted. If you don't have one because you are trying this lab outside of our scheduled session no worries! Visit https://huggingface.co/settings/tokens to create a free account, create a token of `type = READ`, and then copy your access token.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected environment: local\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/Users/jwhorley/Library/Python/3.11/lib/python/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/Users/jwhorley/Library/Python/3.11/lib/python/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/Users/jwhorley/Library/Python/3.11/lib/python/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "✅ Hugging Face token found at ../hf_token.txt\n",
      "🧭 Detected environment: local\n",
      "Loading embedding model for semantic topic matching...\n",
      "🔧 Using text generation mode for local Jupyter.\n",
      "\n",
      "Safe Caption Generator module imported successfully, ready to use!\n"
     ]
    }
   ],
   "source": [
    "# This script auto-detects your environment (Colab or local) and configures everything accordingly.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "\n",
    "# --- Detect Environment ---\n",
    "def get_runtime_env():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return \"colab\"\n",
    "    except ImportError:\n",
    "        return \"local\"\n",
    "\n",
    "env = get_runtime_env()\n",
    "print(f\"Detected environment: {env}\")\n",
    "\n",
    "# --- Install Dependencies ---\n",
    "if env == \"colab\":\n",
    "    %pip install -r MLLAcademy-2025/requirements.txt\n",
    "else:\n",
    "    %pip install -r requirements.txt\n",
    "\n",
    "# --- Hugging Face Token Management ---\n",
    "token_path = Path(\"/content/hf_token.txt\") if env == \"colab\" else Path(\"../hf_token.txt\")\n",
    "\n",
    "if not token_path.exists():\n",
    "    print(\"Please enter your Hugging Face API token:\")\n",
    "    token = getpass(\"Hugging Face Token: \")\n",
    "    with open(token_path, \"w\") as f:\n",
    "        f.write(token.strip())\n",
    "    print(f\"✅ Hugging Face token saved to {token_path}\")\n",
    "else:\n",
    "    print(f\"✅ Hugging Face token found at {token_path}\")\n",
    "\n",
    "# --- Ensure utils folder is in sys.path ---\n",
    "sys.path.append(str(Path(\"/content/MLLAcademy-2025/utils\").resolve()) if env == \"colab\" else str(Path(\"../utils\").resolve()))\n",
    "\n",
    "# --- Import the Safe Caption Generator ---\n",
    "from safe_caption_generator import safe_caption_generator\n",
    "print(\"\\nSafe Caption Generator module imported successfully, ready to use!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function - for printing captions cleanly and export the results to a JSON file\n",
    "# This file will be used later when we generate the images \n",
    "\n",
    "def print_captions(captions):\n",
    "    env = get_runtime_env()\n",
    "    captions_path = Path(\"/content/MLLAcademy-2025/captions.json\") if env == \"colab\" else Path(\"../captions.json\")\n",
    "\n",
    "    with open(captions_path, \"w\") as f:\n",
    "        json.dump(captions, f)\n",
    "\n",
    "    print(f\"✅ Captions saved to {captions_path}\")\n",
    "    print(\"\\n---\\n\\n\")\n",
    "    for i, c in enumerate(captions, 1):\n",
    "        print(f\"Caption {i}: {c}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type in a prompt between the quotes \n",
    "This will assign your topic to the variable `user_input`\n",
    " - Running the cell below will then run the caption generator and print the captions\n",
    " \n",
    "Additionally, we are going to be using a Python function called `safe_caption_generator` to assist us in prompting the LLM. For example, this code is within the function and prompts the LLM prior to its text generation, based on your input: \n",
    "\n",
    "```\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"Write a short, funny meme caption about this topic: {user_input}.\\n\"\n",
    "    \"Only return a single caption, in quotes, with no explanation or extra text.\"\n",
    ")\n",
    "```\n",
    "\n",
    "### We are going to specifically guide our text generation to stay aligned on certain topics.\n",
    "You may find that certain topics will be blocked from use. If you run into a \"try again error message\" please adjust your input. Here are the broad topics we are going to use within this lab for your captions: \n",
    "- \"final exams\"\n",
    "- \"group projects\"\n",
    "- \"studying late\", \n",
    "- \"Monday mornings\"\n",
    "- \"school cafeteria food\"\n",
    "- \"summer break\"\n",
    "- \"forgetting your homework\"\n",
    "- \"getting a pop quiz\"\n",
    "- \"trying to stay awake in class\"\n",
    "- \"sports\"\n",
    "- \"coding projects\"\n",
    "- \"hackathons\"\n",
    "- \"hanging out with friends\"\n",
    "- \"summer weather\"\n",
    "- \"family vacations\"\n",
    "- \"college applications\"\n",
    "-  \"video games\"\n",
    "\n",
    "_You don't have to use these exact words in your `user_input`, but it needs to be semantically similar. For example, \"Going to a baseball game instead of studying\" would match our themes of both `sports` and `forgetting your homework`, and possibly even `studying late`._\n",
    "\n",
    " > Note: This cell may take anywhere from 30 seconds to 2 minutes depending on your prompt and notebook compute resources at the time of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing prompt: 'summer vacation can't come soon enough'\n",
      "✅ Captions saved to ../captions.json\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Caption 1: Sunburnt dreams are made of this: 'Summer vacation will arrive on the 3rd Tuesday' said nobody ever.\n",
      "\n",
      "Caption 2: We're not lazy, we're just on vacation from adulting.\n",
      "\n",
      "Caption 3: Road trip snacks are my love language.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Now we are going to run the safe caption generator based on your input ---\n",
    "# In this cell, we'll test our `safe_caption_generator` function with a sample input. It will:\n",
    "#   - Use your input prompt.\n",
    "#   - Check if the input matches approved topics.\n",
    "#   - Generate 3 captions using a language model.\n",
    "#   - Save the captions to a JSON file for use in later cells.\n",
    "\n",
    "try:\n",
    "    # modify this input to test different prompts \n",
    "    user_input = \"summer vacation can't come soon enough\"\n",
    "    print(f\"Testing prompt: '{user_input}'\")\n",
    "    \n",
    "    # Generate and save 3 meme captions and print each\n",
    "    captions = safe_caption_generator(user_input, num_captions=3)\n",
    "    print_captions(captions)\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"⚠️ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out!\n",
    "Use the box below to enter your meme idea, click \"Generate,\" and see three captions!\n",
    "\n",
    "Each generation is saved in `captions.json` for use in the next part of the lab. Each new generation overwrites that file. If you want to save any specific caption, save it in a new file within your directory. You'll have a chance to select your favorite caption in the next lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c504335395a452287797ff2e9409256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Prompt:', placeholder='Enter your meme idea...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704b4c3b8b9e4e54938de4221daf2f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d895720699467ba05a92bb01cb6445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive Prompt (for Demo in class)\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "input_box = widgets.Text(value='', placeholder='Enter your meme idea...', description='Prompt:')\n",
    "run_button = widgets.Button(description=\"Generate\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def run_on_click(b):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        try:\n",
    "            captions = safe_caption_generator(input_box.value)\n",
    "            # for idx, c in enumerate(captions, 1): # backup code to print each caption rather than use function\n",
    "            #   print(f\"{idx}. {c}\")\n",
    "            print_captions(captions)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error: {e}\")\n",
    "\n",
    "run_button.on_click(run_on_click)\n",
    "display(input_box, run_button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting Guide\n",
    "\n",
    "- If you get a profanity or topic error, verify the input is:\n",
    "  - Clean (no banned phrases)\n",
    "  - Topically close to: studying, group projects, sports, coding, school, etc.\n",
    "\n",
    "- If you get an API error:\n",
    "  - Ensure `hf_token.txt` exists and contains a valid Hugging Face token; if the token is missing, please ask for a new token.\n",
    "  - Ensure `.gitignore` excludes it from version control\n",
    "\n",
    "- If you get no captions back:\n",
    "  - Check output formatting with `print(repr(captions))`\n",
    "  - Rerun cell — model output may vary by seed\n",
    "\n",
    "---\n",
    "✅ Instructor notebook complete. Move on to Notebook A when you're ready.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
